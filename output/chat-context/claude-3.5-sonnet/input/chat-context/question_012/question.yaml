 question: Where is the model used for edits configured?
# CHAT
# CHAT_QUESTION Where is the model used for edits configured?

# CHAT_REPLY The model used for edits is configured in several places within the codebase:
# CHAT_REPLY 
# CHAT_REPLY 1. In the `EditManager` class (`cody_test/vscode/src/edit/manager.ts`), the edit model is set using:
# CHAT_REPLY    ```typescript
# CHAT_REPLY    const model = configuration.model || editModel.get(this.options.authProvider, this.models)
# CHAT_REPLY    ```
# CHAT_REPLY 
# CHAT_REPLY 2. The `editModel` accessor is defined in `cody_test/vscode/src/models/index.ts`:
# CHAT_REPLY    ```typescript
# CHAT_REPLY    export const editModel = createModelAccessor<EditModel>('editModel')
# CHAT_REPLY    ```
# CHAT_REPLY 
# CHAT_REPLY 3. The `getModel` function in `cody_test/vscode/src/models/index.ts` determines which model to use based on the user's authentication status and available models.
# CHAT_REPLY 
# CHAT_REPLY 4. Users can change the model during the edit process. The `MODEL_ITEM` is defined in `cody_test/vscode/src/edit/input/get-items/edit.ts` and allows users to select a different model.
# CHAT_REPLY 
# CHAT_REPLY 5. The available edit models are retrieved using `getEditModelsForUser` function in `cody_test/vscode/src/edit/utils/edit-models.ts`.
# CHAT_REPLY 
# CHAT_REPLY 6. The `ModelProvider` class in `cody_test/lib/shared/src/models/index.ts` manages the available chat and edit models.
# CHAT_REPLY 
# CHAT_REPLY 7. For specific edit intents, the model can be overridden using the `getOverridenModelForIntent` function in `cody_test/vscode/src/edit/utils/edit-models.ts`.
# CHAT_REPLY 
# CHAT_REPLY This multi-layered approach allows for flexibility in model selection based on user status, configuration, and specific edit requirements.

# CONTEXT_ITEMS [{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-items/model.ts:10-25","content":"const getModelProviderIcon = (provider: string): string => {\n    switch (provider) {\n        case 'Anthropic':\n            return '$(anthropic-logo)'\n        case 'OpenAI':\n            return '$(openai-logo)'\n        case 'Mistral':\n            return '$(mistral-logo)'\n        case 'Ollama':\n            return '$(ollama-logo)'\n        case 'Google':\n            return '$(gemini-logo)'\n        default:\n            return ''\n    }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/chat/markdown.ts:76-79","content":"        ...options,\n    })\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-items/model.ts:27-52","content":"export const getModelOptionItems = (\n    modelOptions: ModelProvider[],\n    isCodyPro: boolean\n): EditModelItem[] => {\n    const allOptions = modelOptions.map(modelOption => {\n        const icon = getModelProviderIcon(modelOption.provider)\n        return {\n            label: `${QUICK_PICK_ITEM_EMPTY_INDENT_PREFIX} ${icon} ${modelOption.title}`,\n            description: `by ${modelOption.provider}`,\n            alwaysShow: true,\n            model: modelOption.model,\n            modelTitle: modelOption.title,\n            codyProOnly: modelOption.codyProOnly,\n        }\n    })\n\n    if (!isCodyPro) {\n        return [\n            ...allOptions.filter(option => !option.codyProOnly),\n            { label: 'upgrade to cody pro', kind: vscode.QuickPickItemKind.Separator } as EditModelItem,\n            ...allOptions.filter(option => option.codyProOnly),\n        ]\n    }\n\n    return allOptions\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-input.ts:511-526","content":"                    instruction: instruction.trim(),\n                    userContextFiles: Array.from(selectedContextItems)\n                        .filter(([key]) => instruction.toString().includes(`@${key}`))\n                        .map(([, value]) => value),\n                    model: activeModel,\n                    range: activeRange,\n                    intent: isGenerateIntent(document, activeRange) ? 'add' : 'edit',\n                })\n            },\n        })\n\n        editInput.render(activeTitle, initialValues.initialInputValue?.toString() || '')\n        editInput.input.activeItems = []\n    })\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-items/model.ts:54-74","content":"export const getModelInputItems = (\n    modelOptions: ModelProvider[],\n    activeModel: EditModel,\n    isCodyPro: boolean\n): GetItemsResult => {\n    const modelItems = getModelOptionItems(modelOptions, isCodyPro)\n    const activeItem = modelItems.find(item => item.model === activeModel)\n\n    if (activeItem) {\n        // Update the label of the active item\n        activeItem.label = activeItem.label.replace(\n            QUICK_PICK_ITEM_EMPTY_INDENT_PREFIX,\n            QUICK_PICK_ITEM_CHECKED_PREFIX\n        )\n    }\n\n    return {\n        items: modelItems,\n        activeItem,\n    }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/constants.ts:0-5","content":"import type { EditIntent, EditMode } from './types'\n\nexport const DEFAULT_EDIT_MODE: EditMode = 'edit'\nexport const DEFAULT_EDIT_INTENT: EditIntent = 'edit'\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-items/types.ts:0-13","content":"import type { EditModel } from '@sourcegraph/cody-shared'\nimport type * as vscode from 'vscode'\n\nexport interface EditRangeItem extends vscode.QuickPickItem {\n    range: vscode.Range | (() => Promise<vscode.Range>)\n}\n\nexport interface EditModelItem extends vscode.QuickPickItem {\n    modelTitle: string\n    model: EditModel\n    codyProOnly: boolean\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/prompt/models/openai.ts:14-19","content":"    getEdit(options) {\n        return {\n            ...SHARED_PARAMETERS,\n            prompt: buildGenericPrompt('edit', options),\n        }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/models/index.ts:0-29","content":"import { fetchLocalOllamaModels } from '../llm-providers/ollama/utils'\nimport { CHAT_INPUT_TOKEN_BUDGET, CHAT_OUTPUT_TOKEN_BUDGET } from '../token/constants'\nimport type { ModelContextWindow } from './types'\nimport type { ModelUsage } from './types'\nimport { getModelInfo } from './utils'\n\n/**\n * ModelProvider manages available chat and edit models.\n * It stores a set of available providers and methods to add,\n * retrieve and select between them.\n */\nexport class ModelProvider {\n    // Whether the model is the default model\n    public default = false\n    // Whether the model is only available to Pro users\n    public codyProOnly = false\n    // The name of the provider of the model, e.g. \"Anthropic\"\n    public provider: string\n    // The title of the model, e.g. \"Claude 2.0\"\n    public readonly title: string\n\n    constructor(\n        /**\n         * The model id that includes the provider name & the model name,\n         * e.g. \"anthropic/claude-2.0\"\n         */\n        public readonly model: string,\n        /**\n         * The usage of the model, e.g. chat or edit.\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/models/index.ts:0-25","content":"import type { ChatModel, EditModel, ModelProvider } from '@sourcegraph/cody-shared'\nimport type { AuthProvider } from '../services/AuthProvider'\nimport { localStorage } from '../services/LocalStorageProvider'\n\nasync function setModel(modelID: EditModel, storageKey: string) {\n    // Store the selected model in local storage to retrieve later\n    return localStorage.set(storageKey, modelID)\n}\n\nfunction getModel<T extends string>(\n    authProvider: AuthProvider,\n    models: ModelProvider[],\n    storageKey: string\n): T {\n    const authStatus = authProvider.getAuthStatus()\n    // Free user can only use the default model\n    if (authStatus.isDotCom && authStatus.userCanUpgrade) {\n        return models[0].model as T\n    }\n\n    // Enterprise user can only use the default model\n    // We only support a single model for enterprise users right now\n    if (!authStatus.isDotCom) {\n        return models[0].model as T\n    }\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/prompt/models/claude.ts:15-20","content":"    getEdit(options) {\n        return {\n            ...SHARED_PARAMETERS,\n            prompt: buildGenericPrompt('edit', options),\n        }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/prompt/index.ts:0-32","content":"import * as vscode from 'vscode'\n\nimport {\n    BotResponseMultiplexer,\n    type ChatMessage,\n    type CompletionParameters,\n    type EditModel,\n    type Message,\n    ModelProvider,\n    PromptString,\n    TokenCounter,\n    getSimplePreamble,\n    ps,\n} from '@sourcegraph/cody-shared'\n\nimport type { VSCodeEditor } from '../../editor/vscode-editor'\nimport type { FixupTask } from '../../non-stop/FixupTask'\nimport type { EditIntent } from '../types'\n\nimport { PromptBuilder } from '../../prompt-builder'\nimport { getContext } from './context'\nimport { claude } from './models/claude'\nimport { openai } from './models/openai'\nimport type { EditLLMInteraction, GetLLMInteractionOptions, LLMInteraction } from './type'\n\nconst INTERACTION_MODELS: Record<EditModel, EditLLMInteraction> = {\n    'anthropic/claude-2.0': claude,\n    'anthropic/claude-2.1': claude,\n    'anthropic/claude-instant-1.2': claude,\n    'anthropic/claude-3-opus-20240229': claude,\n    'anthropic/claude-3-sonnet-20240229': claude,\n    'anthropic/claude-3-haiku-20240307': claude,\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/input/get-items/edit.ts:9-12","content":"export const MODEL_ITEM: vscode.QuickPickItem = {\n    label: 'Model',\n    alwaysShow: true,\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/manager.ts:98-122","content":"\n        const editor = getEditor()\n        if (editor.ignored) {\n            void vscode.window.showInformationMessage('Cannot edit Cody ignored file.')\n            return\n        }\n\n        const document = configuration.document || editor.active?.document\n        if (!document) {\n            void vscode.window.showErrorMessage('Please open a file before running a command.')\n            return\n        }\n\n        const proposedRange = configuration.range || editor.active?.selection\n        if (!proposedRange) {\n            return\n        }\n\n        // Set default edit configuration, if not provided\n        // It is possible that these values may be overriden later, e.g. if the user changes them in the edit input.\n        const range = getEditLineSelection(document, proposedRange)\n        const mode = configuration.mode || DEFAULT_EDIT_MODE\n        const model = configuration.model || editModel.get(this.options.authProvider, this.models)\n        const intent = getEditIntent(document, range, configuration.intent)\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/models/utils.ts:85-106","content":"export function getChatModelsFromConfiguration(): ModelProvider[] {\n    const codyConfig = vscode.workspace.getConfiguration('cody')\n    const modelsConfig = codyConfig?.get<ChatModelProviderConfig[]>('dev.models')\n    if (!modelsConfig?.length) {\n        return []\n    }\n\n    const providers: ModelProvider[] = []\n    for (const m of modelsConfig) {\n        const provider = new ModelProvider(\n            `${m.provider}/${m.model}`,\n            [ModelUsage.Chat, ModelUsage.Edit],\n            { input: m.inputTokens ?? CHAT_INPUT_TOKEN_BUDGET, output: m.outputTokens ?? ANSWER_TOKENS },\n            { apiKey: m.apiKey, apiEndpoint: m.apiEndpoint }\n        )\n        provider.codyProOnly = true\n        providers.push(provider)\n    }\n\n    ModelProvider.addProviders(providers)\n    return providers\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/provider.ts:28-55","content":"\ninterface EditProviderOptions extends EditManagerOptions {\n    task: FixupTask\n    controller: FixupController\n}\n\n// Initiates a completion and responds to the result from the LLM. Implements\n// \"tools\" like directing the response into a specific file. Code is forwarded\n// to the FixupTask.\nexport class EditProvider {\n    private insertionResponse: string | null = null\n    private insertionInProgress = false\n    private insertionPromise: Promise<void> | null = null\n    private abortController: AbortController | null = null\n\n    constructor(public config: EditProviderOptions) {}\n\n    public async startEdit(): Promise<void> {\n        return wrapInActiveSpan('command.edit.start', async span => {\n            this.config.controller.startTask(this.config.task)\n            const model = this.config.task.model\n            const contextWindow = ModelProvider.getContextWindowByID(model)\n            const {\n                messages,\n                stopSequences,\n                responseTopic,\n                responsePrefix = '',\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/webviews/chat/models/chatModelContext.tsx:13-15","content":"export function useChatModelContext(): ChatModelContext {\n    return useContext(context)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/TESTING.md:48-63","content":"- [ ] Verify that you can see a list of code lenses with a Cody icon above the generated code: `Show diff`, `Accept`, `Retry`, and `Undo`.\n- [ ] Verify that you can see a diff view of the edit in a new tab by clicking `Show diff`.\n- [ ] Verify that you can prompt Cody to retry the command by clicking `Retry` and entering new instructions.\n- [ ] Verify that you can undo the edit by clicking `Undo`.\n- [ ] Verify that the ghost text disappears by clicking `Accept`.\n\n#### Editing code (Additional Configuration)\n\n- [ ] Highlight a section of code.\n- [ ] Trigger the Edit shortcut with Option+K\n- [ ] Try to add a file to the Edit instruction, by using \"@\" and searching for a file\n- [ ] Try to add a symbol to the Edit instruction, by using \"@#\" and searching for a symbol\n- [ ] Try to change the range of the Edit, by selecting \"Range\". Check that navigating through the options correctly updates the range shown in the editor.\n- [ ] Try to change the model of the Edit, by selecting \"Model\".\n- [ ] Submit edits after changing the above values, and check that the Edit performs correctly (e.g. uses correct range, uses correct context)\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/webviews/chat/models/chatModelContext.tsx:17-20","content":"export function useCurrentChatModel(): ModelProvider | undefined {\n    const { chatModels } = useChatModelContext()\n    return chatModels?.find(model => model.default) ?? chatModels?.[0]\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/types.ts:0-13","content":"/**\n * The intent classification for the edit.\n * Manually determined depending on how the edit is triggered.\n */\nexport type EditIntent = 'add' | 'edit' | 'fix' | 'doc' | 'test'\n\n/**\n * The edit modes that can be used when applying an edit.\n * - 'edit': Modify selected code in place.\n * - 'insert': Insert new code at the selected location.\n */\nexport type EditMode = 'edit' | 'insert'\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/models/index.ts:50-53","content":"\nexport const chatModel = createModelAccessor<ChatModel>('model')\nexport const editModel = createModelAccessor<EditModel>('editModel')\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/utils/edit-models.ts:0-27","content":"import { type AuthStatus, type EditModel, ModelProvider, ModelUsage } from '@sourcegraph/cody-shared'\nimport type { EditIntent } from '../types'\n\nexport function getEditModelsForUser(authStatus: AuthStatus): ModelProvider[] {\n    return ModelProvider.getProviders(ModelUsage.Edit, !authStatus.userCanUpgrade)\n}\n\nexport function getOverridenModelForIntent(intent: EditIntent, currentModel: EditModel): EditModel {\n    switch (intent) {\n        case 'fix':\n            // Fix is a case where we want to ensure that users do not end up with a broken edit model.\n            // It is outside of the typical Edit flow so it is more likely a user could become \"stuck\" here.\n            // TODO: Make the model usage more visible to users outside of the normal edit flow. This means\n            // we could let the user provide any model they want for `fix`.\n            // Issue: https://github.com/sourcegraph/cody/issues/3512\n            return 'anthropic/claude-3-sonnet-20240229'\n        case 'doc':\n            // Doc is a case where we can sacrifice LLM performnace for improved latency and get comparable results.\n            return 'anthropic/claude-3-haiku-20240307'\n        case 'test':\n        case 'add':\n        case 'edit':\n            // Support all model usage for add and edit intents.\n            return currentModel\n    }\n}\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/edit/manager.ts:25-50","content":"import { getEditIntent } from './utils/edit-intent'\nimport { getEditModelsForUser } from './utils/edit-models'\nimport { getEditLineSelection, getEditSmartSelection } from './utils/edit-selection'\n\nexport interface EditManagerOptions {\n    editor: VSCodeEditor\n    chat: ChatClient\n    ghostHintDecorator: GhostHintDecorator\n    authProvider: AuthProvider\n    extensionClient: ExtensionClient\n}\n\n// EditManager handles translating specific edit intents (document, edit) into\n// generic FixupTasks, and pairs a FixupTask with an EditProvider to generate\n// a completion.\nexport class EditManager implements vscode.Disposable {\n    private readonly controller: FixupController\n    private disposables: vscode.Disposable[] = []\n    private editProviders = new WeakMap<FixupTask, EditProvider>()\n    private models: ModelProvider[] = []\n\n    constructor(public options: EditManagerOptions) {\n        this.controller = new FixupController(options.authProvider, options.extensionClient)\n        /**\n         * Entry point to triggering a new Edit.\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/CHANGELOG.md:86-114","content":"### Changed\n\n- Chat: A new design for chat messages, with avatars and a separate context row. [pull/3639](https://github.com/sourcegraph/cody/pull/3639)\n- Chat: The Enhanced Context Settings modal is opened by default for the first chat session. [pull/3547](https://github.com/sourcegraph/cody/pull/3547)\n- Add information on which Cody tier is being used to analytics events. [pull/3508](https://github.com/sourcegraph/cody/pull/3508)\n- Auth: Enable the new onboarding flow that does not require the redirect back to VS Code for everyone. [pull/3574](https://github.com/sourcegraph/cody/pull/3574)\n- Chat: Claude 3 Sonnet is now the default model for every Cody Free or Pro user. [pull/3575](https://github.com/sourcegraph/cody/pull/3575)\n- Edit: Removed a previous Edit shortcut (`Shift+Cmd/Ctrl+v`), use `Opt/Alt+K` to trigger Edits. [pull/3591](https://github.com/sourcegraph/cody/pull/3591)\n- Commands: The `Editor Title Icon` configuration option has been removed from the Cody Settings menu. Users can configure the title bar icon by right-clicking on the title bar. [pull/3677](https://github.com/sourcegraph/cody/pull/3677)\n\n### Feature Flags\n\n> This section covers experiments that run behind feature flags for non-Enterprise users.\n\n- Hover Commands: Cody commands are now integrated with the native hover provider, allowing you to seamlessly access essential commands on mouse hover. [pull/3585](https://github.com/sourcegraph/cody/pull/3585)\n\n## [1.10.2]\n\n### Added\n\n- Cody Enterprise users now have access to an `experimental-openaicompatible` which allows bringing your own LLM via any OpenAI-compatible API. For now, this is only supported with Starchat and specific configurations - but we continue to generalize this work to support more models and OpenAI-compatible endpoints. [pull/3218](https://github.com/sourcegraph/cody/pull/3218)\n\n## [1.10.1]\n\n### Added\n\n- Autocomplete: Add Claude 3 Haiku experimental autocomplete support. [pull/3538](https://github.com/sourcegraph/cody/pull/3538)\n\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/models/types.ts:0-62","content":"import type { ModelProvider } from '.'\n\nexport enum ModelUsage {\n    Chat = 'chat',\n    Edit = 'edit',\n}\n\n// Utility to narrow a model type to a specific model usage\ntype HasUsage<T, I> = T extends { usage: readonly ModelUsage[] }\n    ? I extends T['usage'][number]\n        ? T\n        : never\n    : never\n\ntype Models = typeof ModelProvider\n\n/**\n * Available models for Edit.\n * This is either:\n * - one of the availble options (dotcom)\n * - an unknown `string` (enterprise)\n */\nexport type EditModel =\n    | {\n          [K in keyof Models]: HasUsage<Models[K], ModelUsage.Edit>\n      }[keyof Models]['model']\n    | (string & {})\n\n/**\n * Available models for Chat.\n * This is either:\n * - one of the availble options (dotcom)\n * - an unknown `string` (enterprise)\n */\nexport type ChatModel =\n    | {\n          [K in keyof Models]: HasUsage<Models[K], ModelUsage.Chat>\n      }[keyof Models]['model']\n    | (string & {})\n\nexport interface ModelContextWindow {\n    /**\n     * The token limit reserved for chat input.\n     */\n    input: number\n    /**\n     * The maximum number of tokens that the model can respond with in a single request.\n     */\n    output: number\n    /**\n     * The additional tokens reserved for context.\n     * When not defined, context shares the same token limit as input.\n     */\n    context?: {\n        /**\n         * The token limit reserved for user-added context.\n         * Example: @-mentions.\n         */\n        user?: number\n    }\n}\n"}]

 class: Find logic
