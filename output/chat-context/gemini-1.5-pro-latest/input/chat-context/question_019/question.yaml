 question: Where do we query the embeddings model?
# CHAT
# CHAT_QUESTION Where do we query the embeddings model?

# CHAT_REPLY The embeddings model is queried in the `retrieveEmbeddingBasedContext` function in the `cody_test/vscode/src/local-context/context-ranking.ts` file. 
# CHAT_REPLY 
# CHAT_REPLY Here's a breakdown:
# CHAT_REPLY 
# CHAT_REPLY 1. **`retrieveEmbeddingBasedContext` Function:** This function takes the user's query, the desired number of results, and the model name as input.
# CHAT_REPLY 2. **Service Request:** It makes a request to the language server using the `context-ranking/context-retriever-embedding` endpoint. 
# CHAT_REPLY 3. **Request Parameters:** The request includes the repository path, the user's query, the model name (`modelName`), and the number of results (`numResults`).
# CHAT_REPLY 4. **Response Processing:** The response from the language server contains embedding search results. The code then maps these results to create a list of `EmbeddingsSearchResult` objects.
# CHAT_REPLY 
# CHAT_REPLY Therefore, the actual query to the embeddings model happens on the language server side, triggered by the `context-ranking/context-retriever-embedding` request.

# CONTEXT_ITEMS [{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/models/index.ts:132-134","content":"    public static getProviderByModel(modelID: string): ModelProvider | undefined {\n        return ModelProvider.providers.find(m => m.model === modelID)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:502-541","content":"      },\n      {\n        \"command\": \"cody.embeddings.resolveIssue\",\n        \"title\": \"Cody Embeddings\",\n        \"when\": \"cody.embeddings.hasIssue\"\n      },\n      {\n        \"command\": \"cody.debug.export.logs\",\n        \"category\": \"Cody Debug\",\n        \"group\": \"Debug\",\n        \"title\": \"Export Logsâ€¦\"\n      },\n      {\n        \"command\": \"cody.debug.outputChannel\",\n        \"category\": \"Cody Debug\",\n        \"group\": \"Debug\",\n        \"title\": \"Open Output Channel\"\n      },\n      {\n        \"command\": \"cody.debug.enable.all\",\n        \"category\": \"Cody Debug\",\n        \"group\": \"Debug\",\n        \"title\": \"Enable Debug Mode\",\n        \"when\": \"!config.cody.debug.verbose\"\n      },\n      {\n        \"command\": \"cody.debug.reportIssue\",\n        \"category\": \"Cody Debug\",\n        \"group\": \"Debug\",\n        \"title\": \"Report Issue\"\n      },\n      {\n        \"command\": \"cody.copy.version\",\n        \"category\": \"Cody Debug\",\n        \"group\": \"Debug\",\n        \"icon\": \"$(copy)\",\n        \"title\": \"Copy Cody Extension Version\"\n      }\n    ],\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/webviews/chat/models/chatModelContext.tsx:4-7","content":"export interface ChatModelContext {\n    chatModels?: ModelProvider[]\n    onCurrentChatModelChange?: (model: ModelProvider) => void\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/local-embeddings.ts:103-127","content":"        this.disposables.push(\n            vscode.commands.registerCommand('cody.embeddings.resolveIssue', () =>\n                this.resolveIssueCommand()\n            )\n        )\n\n        // Pick up the initial access token, and whether the account is dotcom.\n        this.accessToken = config.accessToken || undefined\n        this.endpointIsDotcom = isDotCom(config.serverEndpoint)\n\n        this.model = config.testingLocalEmbeddingsModel || 'openai/text-embedding-ada-002'\n        this.endpoint =\n            config.testingLocalEmbeddingsEndpoint || 'https://cody-gateway.sourcegraph.com/v1/embeddings'\n        this.indexLibraryPath = config.testingLocalEmbeddingsIndexLibraryPath\n            ? URI.file(config.testingLocalEmbeddingsIndexLibraryPath)\n            : undefined\n    }\n\n    public dispose(): void {\n        for (const disposable of this.disposables) {\n            disposable.dispose()\n        }\n        this.statusBar?.dispose()\n    }\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/agent/src/cli/evaluate-autocomplete/Queries.ts:40-84","content":"    private async compileQuery(\n        parser: WrappedParser,\n        language: SupportedLanguage,\n        name: QueryName\n    ): Promise<Query | undefined> {\n        const languages = [language, ...(grammarInheritance[language] ?? [])]\n        const queryStrings: string[] = []\n        for (const queryLanguage of languages) {\n            const queryPath = path.join(this.queriesDirectory, queryLanguage, `${name}.scm`)\n            try {\n                const stat = await fspromises.stat(queryPath)\n                if (!stat.isFile()) {\n                    continue\n                }\n            } catch {\n                if (this.queryDirectoryExists === undefined) {\n                    try {\n                        this.queryDirectoryExists = (\n                            await fspromises.stat(this.queriesDirectory)\n                        ).isDirectory()\n                        if (!this.queryDirectoryExists) {\n                            throw new Error(\n                                `Query directory ${this.queriesDirectory} is not a directory. To fix this problem, update the value of the flag --queries-directory <path>`\n                            )\n                        }\n                    } catch {\n                        throw new Error(\n                            `Query directory ${this.queriesDirectory} does not exist. To fix this problem, update the value of the flag --queries-directory <path>`\n                        )\n                    }\n                }\n                continue\n            }\n            const queryString = await fspromises.readFile(queryPath)\n            queryStrings.push(queryString.toString())\n        }\n        const uncompiled: UncompiledQuery = {\n            language,\n            queryName: name,\n            queryString: queryStrings.join('\\n\\n'),\n        }\n        const compiled = compileQuery(uncompiled, parser)\n        this.cache.push(compiled)\n        return compiled.compiledQuery\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/agent/src/cli/scip-codegen/scip.ts:3000-3017","content":"                writer.writeMessage(22, this.super_type, () => this.super_type.serialize(writer))\n            if (this.has_constant_type)\n                writer.writeMessage(23, this.constant_type, () => this.constant_type.serialize(writer))\n            if (this.has_intersection_type)\n                writer.writeMessage(17, this.intersection_type, () =>\n                    this.intersection_type.serialize(writer)\n                )\n            if (this.has_union_type)\n                writer.writeMessage(18, this.union_type, () => this.union_type.serialize(writer))\n            if (this.has_with_type)\n                writer.writeMessage(19, this.with_type, () => this.with_type.serialize(writer))\n            if (this.has_structural_type)\n                writer.writeMessage(7, this.structural_type, () =>\n                    this.structural_type.serialize(writer)\n                )\n            if (this.has_annotated_type)\n                writer.writeMessage(8, this.annotated_type, () => this.annotated_type.serialize(writer))\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/agent/src/cli/evaluate-autocomplete/Queries.ts:21-38","content":"    public async loadQuery(\n        parser: WrappedParser,\n        language: SupportedLanguage,\n        name: QueryName\n    ): Promise<Query | undefined> {\n        const fromCache = this.cache.find(\n            compiled => compiled.language === language && compiled.queryName === name\n        )\n        if (fromCache) {\n            return fromCache.compiledQuery\n        }\n        try {\n            return await this.compileQuery(parser, language, name)\n        } catch (error) {\n            console.error(`Queries.loadQuery(): ${language}/${name}`, error)\n            process.exit(1)\n        }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/completions/providers/fireworks.ts:68-95","content":"\n// Model identifiers can be found in https://docs.fireworks.ai/explore/ and in our internal\n// conversations\nconst MODEL_MAP = {\n    // Virtual model strings. Cody Gateway will map to an actual model\n    starcoder: 'fireworks/starcoder',\n    'starcoder-16b': 'fireworks/starcoder-16b',\n    'starcoder-7b': 'fireworks/starcoder-7b',\n    'starcoder2-15b': 'fireworks/starcoder2-15b',\n    'starcoder2-7b': 'fireworks/starcoder2-7b',\n\n    // Fireworks model identifiers\n    'llama-code-13b': 'fireworks/accounts/fireworks/models/llama-v2-13b-code',\n}\n\ntype FireworksModel =\n    | keyof typeof MODEL_MAP\n    // `starcoder-hybrid` uses the 16b model for multiline requests and the 7b model for single line\n    | 'starcoder-hybrid'\n    // `starcoder2-hybrid` uses the 15b model for multiline requests and the 7b model for single line\n    | 'starcoder2-hybrid'\n\nfunction getMaxContextTokens(model: FireworksModel): number {\n    switch (model) {\n        case 'starcoder':\n        case 'starcoder2-hybrid':\n        case 'starcoder2-15b':\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/tree-sitter/query-sdk.test.ts:0-46","content":"import { afterEach, describe, expect, it } from 'vitest'\n\nimport { SupportedLanguage } from './grammars'\nimport { resetParsersCache } from './parser'\nimport { getDocumentQuerySDK } from './query-sdk'\nimport { initTreeSitterParser } from './test-helpers'\n\ndescribe('getDocumentQuerySDK', () => {\n    afterEach(() => {\n        resetParsersCache()\n    })\n\n    it.each([\n        { languageId: SupportedLanguage.javascript },\n        { languageId: SupportedLanguage.typescript },\n        { languageId: SupportedLanguage.javascriptreact },\n        { languageId: SupportedLanguage.typescriptreact },\n        { languageId: SupportedLanguage.go },\n        { languageId: SupportedLanguage.python },\n    ])('returns valid SDK for $languageId', async ({ languageId }) => {\n        const nonInitializedSDK = getDocumentQuerySDK(languageId)\n        expect(nonInitializedSDK).toBeNull()\n\n        const parser = await initTreeSitterParser(languageId)\n        expect(parser).toBeTruthy()\n\n        const sdk = getDocumentQuerySDK(languageId)\n        expect(sdk?.queries.intents).toBeTruthy()\n    })\n\n    it.each([\n        { languageId: SupportedLanguage.csharp },\n        { languageId: SupportedLanguage.cpp },\n        { languageId: SupportedLanguage.csharp },\n        { languageId: SupportedLanguage.php },\n    ])('returns null for $languageId because queries are not defined', async ({ languageId }) => {\n        const nonInitializedSDK = getDocumentQuerySDK(languageId)\n        expect(nonInitializedSDK).toBeNull()\n\n        const parser = await initTreeSitterParser(languageId)\n        expect(parser).toBeTruthy()\n\n        const sdk = getDocumentQuerySDK(languageId)\n        expect(sdk).toBeNull()\n    })\n})\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/index.ts:0-26","content":"// Add anything else here that needs to be used outside of this library.\n\nexport { ModelProvider } from './models'\nexport { type ChatModel, type EditModel, ModelUsage, type ModelContextWindow } from './models/types'\nexport { getDotComDefaultModels } from './models/dotcom'\nexport {\n    getProviderName,\n    getModelInfo,\n} from './models/utils'\nexport { BotResponseMultiplexer } from './chat/bot-response-multiplexer'\nexport { ChatClient } from './chat/chat'\nexport { ignores, isCodyIgnoredFile } from './cody-ignore/context-filter'\nexport {\n    IgnoreHelper,\n    CODY_IGNORE_POSIX_GLOB,\n    type IgnoreFileContent,\n    CODY_IGNORE_URI_PATH,\n} from './cody-ignore/ignore-helper'\nexport { renderCodyMarkdown } from './chat/markdown'\nexport { getSimplePreamble } from './chat/preamble'\nexport type {\n    SerializedChatInteraction,\n    SerializedChatTranscript,\n} from './chat/transcript'\nexport { serializeChatMessage } from './chat/transcript'\nexport { errorToChatError, DEFAULT_EVENT_SOURCE } from './chat/transcript/messages'\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/tree-sitter/query-sdk.ts:0-550","content":"import { findLast } from 'lodash'\nimport type { Position, TextDocument } from 'vscode'\nimport type {\n    Language,\n    Point,\n    Query,\n    QueryCapture,\n    SyntaxNode,\n    Tree,\n    default as Parser,\n} from 'web-tree-sitter'\n\nimport { type SupportedLanguage, isSupportedLanguage } from './grammars'\nimport { getCachedParseTreeForDocument } from './parse-tree-cache'\nimport { type WrappedParser, getParser } from './parser'\nimport { type CompletionIntent, type QueryName, intentPriority, languages } from './queries'\n\ninterface ParsedQuery {\n    compiled: Query\n    raw: string\n}\ntype ResolvedQueries = {\n    [name in QueryName]: ParsedQuery\n}\n\nconst QUERIES_LOCAL_CACHE: Partial<Record<SupportedLanguage, ResolvedQueries & QueryWrappers>> = {}\n\n/**\n * Reads all language queries from disk and parses them.\n * Saves queries the local cache for further use.\n */\nexport function initQueries(language: Language, languageId: SupportedLanguage, parser: Parser): void {\n    const cachedQueries = QUERIES_LOCAL_CACHE[languageId]\n    if (cachedQueries) {\n        return\n    }\n\n    const languageQueries = languages[languageId]\n    if (languageQueries === undefined) {\n        return\n    }\n\n    const queryEntries = Object.entries(languageQueries).map(([name, raw]) => {\n        return [\n            name,\n            {\n                raw,\n                compiled: language.query(raw),\n            },\n        ] as const\n    })\n\n    const queries = Object.fromEntries<ParsedQuery>(queryEntries) as ResolvedQueries\n\n    QUERIES_LOCAL_CACHE[languageId] = {\n        ...queries,\n        ...getLanguageSpecificQueryWrappers(queries, parser, languageId),\n    }\n}\n\nexport interface DocumentQuerySDK {\n    parser: WrappedParser\n    queries: ResolvedQueries & QueryWrappers\n    language: SupportedLanguage\n}\n\n/**\n * Returns the query SDK only if the language has queries defined and\n * the relevant language parser is initialized.\n */\nexport function getDocumentQuerySDK(language: string): DocumentQuerySDK | null {\n    if (!isSupportedLanguage(language)) {\n        return null\n    }\n\n    const parser = getParser(language)\n    const queries = QUERIES_LOCAL_CACHE[language]\n\n    if (!parser || !queries) {\n        return null\n    }\n\n    return {\n        parser,\n        queries,\n        language,\n    }\n}\n\nexport interface QueryWrappers {\n    getSinglelineTrigger: (\n        node: SyntaxNode,\n        start: Point,\n        end?: Point\n    ) => [] | readonly [{ readonly node: SyntaxNode; readonly name: 'trigger' }]\n    getCompletionIntent: (\n        node: SyntaxNode,\n        start: Point,\n        end?: Point\n    ) => [] | readonly [{ readonly node: SyntaxNode; readonly name: CompletionIntent }]\n    getDocumentableNode: (\n        node: SyntaxNode,\n        start: Point,\n        end?: Point\n    ) =>\n        | []\n        | readonly [\n              {\n                  symbol?: QueryCapture\n                  range?: QueryCapture\n                  insertionPoint?: QueryCapture\n                  meta: { showHint: boolean }\n              },\n          ]\n    getGraphContextIdentifiers: (node: SyntaxNode, start: Point, end?: Point) => QueryCapture[]\n    getEnclosingFunction: (node: SyntaxNode, start: Point, end?: Point) => QueryCapture[]\n    getTestableNode: (\n        node: SyntaxNode,\n        start: Point,\n        end?: Point\n    ) =>\n        | []\n        | readonly [\n              {\n                  symbol?: QueryCapture\n                  range?: QueryCapture\n                  meta: { showHint: boolean }\n              },\n          ]\n}\n\n/**\n * Query wrappers with custom post-processing logic.\n */\nfunction getLanguageSpecificQueryWrappers(\n    queries: ResolvedQueries,\n    _parser: Parser,\n    languageId: SupportedLanguage\n): QueryWrappers {\n    return {\n        getSinglelineTrigger: (root, start, end) => {\n            const captures = queries.singlelineTriggers.compiled.captures(root, start, end)\n            const { trigger, block } = getTriggerNodeWithBlockStaringAtPoint(captures, start)\n\n            if (!trigger || !block || !isBlockNodeEmpty(block)) {\n                return []\n            }\n\n            return [{ node: trigger, name: 'trigger' }] as const\n        },\n        getCompletionIntent: (root, start, end) => {\n            const captures = queries.intents.compiled.captures(root, start, end)\n\n            const { intentCapture } = getIntentFromCaptures(captures, start)\n\n            if (!intentCapture) {\n                return []\n            }\n\n            return [{ node: intentCapture.node, name: intentCapture.name as CompletionIntent }] as const\n        },\n        getDocumentableNode: (root, start, end) => {\n            const captures = queries.documentableNodes.compiled.captures(\n                root,\n                { ...start, column: 0 },\n                end ? { ...end, column: Number.MAX_SAFE_INTEGER } : undefined\n            )\n\n            const symbolCaptures = []\n            const rangeCaptures = []\n\n            for (const capture of captures) {\n                if (capture.name.startsWith('range')) {\n                    rangeCaptures.push(capture)\n                } else if (capture.name.startsWith('symbol')) {\n                    symbolCaptures.push(capture)\n                }\n            }\n\n            const symbol = findLast(symbolCaptures, ({ node }) => {\n                return (\n                    node.startPosition.row === start.row &&\n                    (node.startPosition.column <= start.column || node.startPosition.row < start.row) &&\n                    (start.column <= node.endPosition.column || start.row < node.endPosition.row)\n                )\n            })\n\n            const documentableRanges = rangeCaptures.filter(({ node }) => {\n                return (\n                    node.startPosition.row <= start.row &&\n                    (start.column <= node.endPosition.column || start.row < node.endPosition.row)\n                )\n            })\n            const range = documentableRanges.at(-1)\n\n            let insertionPoint: QueryCapture | undefined\n            if (languageId === 'python' && range) {\n                /**\n                 * Python is a special case for generating documentation.\n                 * The insertion point of the documentation should differ if the symbol is a function or class.\n                 * We need to query again for an insertion point, this time using the correct determined range.\n                 *\n                 * See https://peps.python.org/pep-0257/ for the documentation conventions for Python.\n                 */\n                const insertionCaptures = queries.documentableNodes.compiled\n                    .captures(root, range.node.startPosition, range.node.endPosition)\n                    .filter(({ name }) => name.startsWith('insertion'))\n\n                insertionPoint = insertionCaptures.find(\n                    ({ node }) =>\n                        node.startIndex >= range.node.startIndex && node.endIndex <= range.node.endIndex\n                )\n            }\n\n            /**\n             * Modify where we look for a docstring depending on the language and syntax.\n             * For Python functions and classes, we will have a provided `insertionPoint`, use the line below this.\n             * For all other cases, docstrings should be attached above the symbol range, use this.\n             */\n            const docStringLine =\n                languageId === 'python' && insertionPoint\n                    ? insertionPoint.node.startPosition.row + 1\n                    : start.row - 1\n            const docstringCaptures = queries.documentableNodes.compiled\n                .captures(\n                    root,\n                    { row: docStringLine, column: 0 },\n                    { row: docStringLine, column: Number.MAX_SAFE_INTEGER }\n                )\n                .filter(node => node.name.startsWith('comment'))\n\n            /**\n             * Heuristic to determine if we should show a prominent hint for the symbol.\n             * 1. If there is only one documentable range for this position, we can be confident it makes sense to document. Show the hint.\n             * 2. Otherwise, only show the hint if the symbol is a function\n             * 3. Don't show hint if there is no docstring already present.\n             */\n            const showHint = Boolean(\n                (documentableRanges.length === 1 || symbol?.name.includes('function')) &&\n                    docstringCaptures.length === 0\n            )\n\n            return [\n                {\n                    symbol,\n                    range,\n                    insertionPoint,\n                    meta: { showHint },\n                },\n            ]\n        },\n        getGraphContextIdentifiers: (root, start, end) => {\n            return queries.graphContextIdentifiers.compiled.captures(root, start, end)\n        },\n        getEnclosingFunction: (root, start, end) => {\n            const captures = queries.enclosingFunction.compiled\n                .captures(root, start, end)\n                .filter(capture => capture.name.startsWith('range'))\n\n            const firstEnclosingFunction = findLast(captures, ({ node }) => {\n                return (\n                    node.startPosition.row <= start.row &&\n                    (start.column <= node.endPosition.column || start.row < node.endPosition.row)\n                )\n            })\n\n            if (!firstEnclosingFunction) {\n                return []\n            }\n\n            return [firstEnclosingFunction]\n        },\n        getTestableNode: (root, start, end) => {\n            const captures = queries.enclosingFunction.compiled.captures(\n                root,\n                { ...start, column: 0 },\n                end ? { ...end, column: Number.MAX_SAFE_INTEGER } : undefined\n            )\n            const symbolCaptures = []\n            const rangeCaptures = []\n\n            for (const capture of captures) {\n                if (capture.name.startsWith('range')) {\n                    rangeCaptures.push(capture)\n                } else if (capture.name.startsWith('symbol')) {\n                    symbolCaptures.push(capture)\n                }\n            }\n\n            const symbol = findLast(symbolCaptures, ({ node }) => {\n                return (\n                    node.startPosition.row === start.row &&\n                    (node.startPosition.column <= start.column || node.startPosition.row < start.row) &&\n                    (start.column <= node.endPosition.column || start.row < node.endPosition.row)\n                )\n            })\n\n            const testableRanges = rangeCaptures.filter(({ node }) => {\n                return (\n                    node.startPosition.row <= start.row &&\n                    (start.column <= node.endPosition.column || start.row < node.endPosition.row)\n                )\n            })\n            const range = testableRanges.at(-1)\n\n            /**\n             * Heuristic to determine if we should show a prominent hint for the symbol.\n             * 1. If there is only one testable range for this position, we can be confident it makes sense to test. Show the hint.\n             * 2. TODO: Look for usages of this function in test files, if it's already used then don't show the hint.\n             */\n            const showHint = Boolean(testableRanges.length === 1)\n\n            return [\n                {\n                    symbol,\n                    range,\n                    meta: { showHint },\n                },\n            ]\n        },\n    }\n}\n\n// TODO: check if the block parent is empty in the consumer.\n// Tracking: https://github.com/sourcegraph/cody/issues/1452\nfunction getIntentFromCaptures(\n    captures: QueryCapture[],\n    cursor: Point\n): { cursorCapture?: Parser.QueryCapture; intentCapture?: Parser.QueryCapture } {\n    const emptyResult = {\n        cursorCapture: undefined,\n        intentCapture: undefined,\n    }\n\n    if (!captures.length) {\n        return emptyResult\n    }\n\n    // Find the cursor capture group if exists.\n    const [cursorCapture] = sortByIntentPriority(\n        captures.filter(capture => {\n            const { name, node } = capture\n\n            const matchesCursorPosition =\n                node.startPosition.column === cursor.column && node.startPosition.row === cursor.row\n\n            return name.endsWith('.cursor') && matchesCursorPosition\n        })\n    )\n\n    // Find the corresponding preceding intent capture that matches the cursor capture name.\n    const intentCapture = findLast(captures, capture => {\n        return capture.name === withoutCursorSuffix(cursorCapture?.name)\n    })\n\n    if (cursorCapture && intentCapture) {\n        return { cursorCapture, intentCapture }\n    }\n\n    // If we didn't find a multinode intent, use the most nested atomic capture group.\n    // Atomic capture groups are matches with one node and `!` at the end the capture group name.\n    const atomicCapture = findLast(captures, capture => {\n        const enclosesCursor =\n            (capture.node.startPosition.column <= cursor.column ||\n                capture.node.startPosition.row < cursor.row) &&\n            (cursor.column <= capture.node.endPosition.column ||\n                cursor.row < capture.node.endPosition.row)\n\n        return capture.name.endsWith('!') && enclosesCursor\n    })\n\n    if (atomicCapture) {\n        return {\n            intentCapture: {\n                ...atomicCapture,\n                // Remove `!` from the end of the capture name.\n                name: atomicCapture.name.slice(0, -1),\n            },\n        }\n    }\n\n    return emptyResult\n}\n\nfunction sortByIntentPriority(captures: QueryCapture[]): QueryCapture[] {\n    return captures.sort((a, b) => {\n        return (\n            intentPriority.indexOf(withoutCursorSuffix(a.name) as CompletionIntent) -\n            intentPriority.indexOf(withoutCursorSuffix(b.name) as CompletionIntent)\n        )\n    })\n}\n\nfunction withoutCursorSuffix(name?: string): string | undefined {\n    return name?.split('.').slice(0, -1).join('.')\n}\n\nfunction getTriggerNodeWithBlockStaringAtPoint(\n    captures: QueryCapture[],\n    point: Point\n): { trigger?: SyntaxNode; block?: SyntaxNode } {\n    const emptyResult = {\n        trigger: undefined,\n        block: undefined,\n    }\n\n    if (!captures.length) {\n        return emptyResult\n    }\n\n    const blockStart = getNodeIfMatchesPoint({\n        captures,\n        name: 'block_start',\n        // Taking the last result to get the most nested node.\n        // See https://github.com/tree-sitter/tree-sitter/discussions/2067\n        index: -1,\n        point,\n    })\n\n    const trigger = getCapturedNodeAt({\n        captures,\n        name: 'trigger',\n        index: -1,\n    })\n\n    const block = blockStart?.parent\n\n    if (!blockStart || !block || !trigger) {\n        return emptyResult\n    }\n\n    // Verify that the block node ends at the same position as the trigger node.\n    if (trigger.endIndex !== block?.endIndex) {\n        return emptyResult\n    }\n\n    return { trigger, block }\n}\n\ninterface GetNodeIfMatchesPointParams {\n    captures: QueryCapture[]\n    name: string\n    index: number\n    point: Point\n}\n\nfunction getNodeIfMatchesPoint(params: GetNodeIfMatchesPointParams): SyntaxNode | null {\n    const { captures, name, index, point } = params\n\n    const node = getCapturedNodeAt({ captures, name, index })\n\n    if (node && node.startPosition.column === point.column && node.startPosition.row === point.row) {\n        return node\n    }\n\n    return null\n}\n\ninterface GetCapturedNodeAtParams {\n    captures: QueryCapture[]\n    name: string\n    index: number\n}\n\nfunction getCapturedNodeAt(params: GetCapturedNodeAtParams): SyntaxNode | null {\n    const { captures, name, index } = params\n\n    return captures.filter(capture => capture.name === name).at(index)?.node || null\n}\n\n/**\n * Consider a block empty if it does not have any named children or is missing its closing tag.\n */\nfunction isBlockNodeEmpty(node: SyntaxNode | null): boolean {\n    // Consider a node empty if it does not have any named children.\n    const isBlockEmpty = node?.children.filter(c => c.isNamed()).length === 0\n    const isMissingBlockEnd = Boolean(node?.lastChild?.isMissing())\n\n    return isBlockEmpty || isMissingBlockEnd\n}\n\ninterface QueryPoints {\n    startPoint: Point\n    endPoint: Point\n}\n\nexport function positionToQueryPoints(position: Pick<Position, 'line' | 'character'>): QueryPoints {\n    const startPoint = {\n        row: position.line,\n        column: position.character,\n    }\n\n    const endPoint = {\n        row: position.line,\n        // Querying around one character after trigger position.\n        column: position.character + 1,\n    }\n\n    return { startPoint, endPoint }\n}\n\ntype ExecQueryWrapperParams<T> = {\n    queryWrapper: T\n} & (\n    | {\n          document: TextDocument\n          queryPoints: QueryPoints\n      }\n    | {\n          document: TextDocument\n          position: Pick<Position, 'line' | 'character'>\n      }\n    | {\n          tree: Tree\n          languageId: string\n          queryPoints: QueryPoints\n      }\n    | {\n          tree: Tree\n          languageId: string\n          position: Pick<Position, 'line' | 'character'>\n      }\n)\n\nexport function execQueryWrapper<T extends keyof QueryWrappers>(\n    params: ExecQueryWrapperParams<T>\n): ReturnType<QueryWrappers[T]> | never[] {\n    const { queryWrapper } = params\n\n    const treeToQuery =\n        'document' in params ? getCachedParseTreeForDocument(params.document)?.tree : params.tree\n    const languageId = 'document' in params ? params.document.languageId : params.languageId\n    const documentQuerySDK = getDocumentQuerySDK(languageId as SupportedLanguage)\n\n    const queryPoints =\n        'position' in params ? positionToQueryPoints(params.position) : params.queryPoints\n    const { startPoint, endPoint } = queryPoints\n\n    if (documentQuerySDK && treeToQuery) {\n        return documentQuerySDK.queries[queryWrapper](\n            treeToQuery.rootNode,\n            startPoint,\n            endPoint\n        ) as ReturnType<QueryWrappers[T]>\n    }\n\n    return []\n}\n\nexport type { CompletionIntent }\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/pnpm-lock.yaml:7525-7552","content":"      '@esbuild/linux-arm64': 0.20.2\n      '@esbuild/linux-ia32': 0.20.2\n      '@esbuild/linux-loong64': 0.20.2\n      '@esbuild/linux-mips64el': 0.20.2\n      '@esbuild/linux-ppc64': 0.20.2\n      '@esbuild/linux-riscv64': 0.20.2\n      '@esbuild/linux-s390x': 0.20.2\n      '@esbuild/linux-x64': 0.20.2\n      '@esbuild/netbsd-x64': 0.20.2\n      '@esbuild/openbsd-x64': 0.20.2\n      '@esbuild/sunos-x64': 0.20.2\n      '@esbuild/win32-arm64': 0.20.2\n      '@esbuild/win32-ia32': 0.20.2\n      '@esbuild/win32-x64': 0.20.2\n    dev: true\n\n  /escalade@3.1.1:\n    resolution: {integrity: sha512-k0er2gUkLf8O0zKJiAhmkTnJlTvINGv7ygDNPbeIsX/TJjGJZHuh9B2UxbsaEkmlEo9MfhrSzmhIlhRlI2GXnw==}\n    engines: {node: '>=6'}\n\n  /escalade@3.1.2:\n    resolution: {integrity: sha512-ErCHMCae19vR8vQGe50xIsVomy19rg6gFu3+r3jkEO46suLMWBksvVyoGgQV+jOfl84ZSOSlmv6Gxa89PmTGmA==}\n    engines: {node: '>=6'}\n    dev: true\n\n  /escape-html@1.0.3:\n    resolution: {integrity: sha512-NiSupZ4OeuGwr68lGIeym/ksIZMJodUGOSCZ/FSnTxcrekbvqrgdUxlJOMpijaKZVjAJrWrGs/6Jy8OMuyj9ow==}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/jsonrpc/embeddings-protocol.ts:0-125","content":"/**\n * The protocol for communicating between Cody and local embeddings.\n */\n\ninterface InitializeParams {\n    codyGatewayEndpoint: string\n    indexPath: string\n    chunkingPolicy?: ChunkingPolicy\n}\n\ninterface ChunkingPolicy {\n    maxFileSizeBytes: number\n    pathsToExcludeRegexp: string\n}\n\ninterface QueryParams {\n    repoName: string\n    query: string\n    numResults: number\n}\n\nexport interface QueryResultSet {\n    results: QueryResult[]\n}\n\ninterface QueryResult {\n    fileName: string\n    startLine: number\n    endLine: number\n    content: string\n}\n\ninterface IndexHealthRequest {\n    // The name of the repository to scrutinize the index for. Note, this\n    // is a repo name, like github.com/sourcegraph/cody, not a file path.\n    repoName: string\n}\n\ntype IndexHealthResult = IndexHealthResultFound | IndexHealthResultNotFound\n\nexport interface IndexHealthResultFound {\n    type: 'found'\n    repoName: string\n    format: 'App' | 'LocalEmbeddings'\n    commit: string\n    model: string\n    dimension: number\n    numItems: number\n    numItemsDeleted: number\n    numItemsNeedEmbedding: number\n    numItemsFailed: number\n    numFiles: number\n}\n\ninterface IndexHealthResultNotFound {\n    type: 'notFound'\n    repoName: string\n}\n\nexport interface IndexRequest {\n    repoPath: string\n    mode: IndexRequestMode\n}\n\ntype IndexRequestMode = IndexRequestModeNew | IndexRequestModeContinue\n\ninterface IndexRequestModeNew {\n    type: 'new'\n    model: string\n    dimension: number\n}\n\ninterface IndexRequestModeContinue {\n    type: 'continue'\n}\n\ninterface IndexResult {\n    repoName: string\n}\n\ninterface LoadResult {\n    repoName: string\n}\nexport type Requests = {\n    'embeddings/echo': [string, string]\n    // Instruct local embeddings to index the specified repository path.\n    'embeddings/index': [IndexRequest, IndexResult]\n    // Get statistics for the index for a given repository name.\n    'embeddings/index-health': [IndexHealthRequest, IndexHealthResult]\n    // Initializes the local embeddings service. You must call this first.\n    'embeddings/initialize': [InitializeParams, Record<string, never>]\n    // Searches for and loads an index for the specified repository name.\n    'embeddings/load': [string, LoadResult]\n    // Queries loaded index.\n    'embeddings/query': [QueryParams, QueryResultSet]\n    // Sets the Sourcegraph access token.\n    'embeddings/set-token': [string, Record<string, never>]\n    // Shuts down the local embeddings service.\n    'embeddings/shutdown': [Record<string, never>, Record<string, never>]\n}\n\ntype ProgressValue = Progress | ProgressError | ProgressDone\n\ninterface Progress {\n    type: 'progress'\n    currentPath: string\n    repoName: string\n    repoPath: string\n    numItems: number\n    totalItems: number\n}\n\ninterface ProgressDone {\n    type: 'done'\n    repoName: string\n}\n\ninterface ProgressError {\n    type: 'error'\n    repoName: string\n    message: string\n}\nexport type Notifications = {\n    'embeddings/progress': [ProgressValue]\n}\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:962-993","content":"        \"cody.experimental.simpleChatContext\": {\n          \"order\": 99,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Uses the new simplifed chat context fetcher\",\n          \"default\": true\n        },\n        \"cody.experimental.ollamaChat\": {\n          \"order\": 99,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Enable local Ollama models for chat and commands\",\n          \"default\": false\n        },\n        \"cody.experimental.symfContext\": {\n          \"order\": 99,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Enable symf code search context for chat\",\n          \"default\": true\n        },\n        \"cody.experimental.symf.path\": {\n          \"order\": 99,\n          \"type\": \"string\",\n          \"markdownDescription\": \"Path to symf binary\",\n          \"default\": \"\"\n        },\n        \"cody.experimental.tracing\": {\n          \"order\": 99,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Enable OpenTelemetry tracing\",\n          \"default\": false\n        },\n        \"cody.debug.verbose\": {\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/context-ranking.ts:279-311","content":"    public async searchModelSpecificEmbeddings(\n        text: PromptString,\n        numResults: number\n    ): Promise<ContextItem[]> {\n        return wrapInActiveSpan('chat.context.model-specific-embeddings.local', async () => {\n            logDebug(\n                'SimpleChatPanelProvider',\n                'getEnhancedContext > searching model specific embeddings'\n            )\n            const contextItems: ContextItem[] = []\n            const modelName = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n            const embeddingsResults = await this.retrieveEmbeddingBasedContext(\n                text,\n                numResults,\n                modelName\n            )\n            for (const result of embeddingsResults) {\n                const range = new vscode.Range(\n                    new vscode.Position(result.startLine, 0),\n                    new vscode.Position(result.endLine, 0)\n                )\n\n                contextItems.push({\n                    type: 'file',\n                    uri: result.uri,\n                    range,\n                    content: result.content,\n                    source: ContextItemSource.Embeddings,\n                })\n            }\n            return contextItems\n        })\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/chat/chat-view/SimpleChatPanelProvider.ts:36-59","content":"import type { LocalEmbeddingsController } from '../../local-context/local-embeddings'\nimport type { SymfRunner } from '../../local-context/symf'\nimport { logDebug } from '../../log'\nimport type { AuthProvider } from '../../services/AuthProvider'\nimport { telemetryService } from '../../services/telemetry'\nimport { telemetryRecorder } from '../../services/telemetry-v2'\nimport type { TreeViewProvider } from '../../services/tree-views/TreeViewProvider'\nimport {\n    handleCodeFromInsertAtCursor,\n    handleCodeFromSaveToNewFile,\n    handleCopiedCode,\n} from '../../services/utils/codeblock-action-tracker'\nimport { openExternalLinks, openLocalFileWithRange } from '../../services/utils/workspace-action'\nimport { TestSupport } from '../../test-support'\nimport { countGeneratedCode } from '../utils'\n\nimport type { Span } from '@opentelemetry/api'\nimport { captureException } from '@sentry/core'\nimport type {\n    ContextItemFile,\n    ContextItemWithContent,\n} from '@sourcegraph/cody-shared/src/codebase-context/messages'\nimport { ModelUsage } from '@sourcegraph/cody-shared/src/models/types'\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/context/remote-search.ts:111-118","content":"    public async query(query: PromptString): Promise<ContextSearchResult[]> {\n        // Sending prompt strings to the Sourcegraph search backend is fine.\n        const result = await graphqlClient.contextSearch(this.getRepoIdSet(), query.toString())\n        if (result instanceof Error) {\n            throw result\n        }\n        return result || []\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/local-embeddings.ts:30-58","content":"\nexport type LocalEmbeddingsConfig = Pick<\n    ConfigurationWithAccessToken,\n    'serverEndpoint' | 'accessToken'\n> & {\n    testingLocalEmbeddingsModel: string | undefined\n    testingLocalEmbeddingsEndpoint: string | undefined\n    testingLocalEmbeddingsIndexLibraryPath: string | undefined\n}\n\nfunction getIndexLibraryPath(): FileURI {\n    switch (process.platform) {\n        case 'darwin':\n            return URI.file(`${process.env.HOME}/Library/Caches/com.sourcegraph.cody/embeddings`)\n        case 'linux':\n            return URI.file(`${process.env.HOME}/.cache/com.sourcegraph.cody/embeddings`)\n        case 'win32':\n            return URI.file(`${process.env.LOCALAPPDATA}\\\\com.sourcegraph.cody\\\\embeddings`)\n        default:\n            throw new Error(`Unsupported platform: ${process.platform}`)\n    }\n}\n\ninterface RepoState {\n    repoName: string | false\n    indexable: boolean\n    errorReason: GetFieldType<LocalEmbeddingsProvider, 'errorReason'>\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/testutils/uri.ts:72-74","content":"    public get query(): string {\n        return this.uri.query\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/models/types.ts:0-62","content":"import type { ModelProvider } from '.'\n\nexport enum ModelUsage {\n    Chat = 'chat',\n    Edit = 'edit',\n}\n\n// Utility to narrow a model type to a specific model usage\ntype HasUsage<T, I> = T extends { usage: readonly ModelUsage[] }\n    ? I extends T['usage'][number]\n        ? T\n        : never\n    : never\n\ntype Models = typeof ModelProvider\n\n/**\n * Available models for Edit.\n * This is either:\n * - one of the availble options (dotcom)\n * - an unknown `string` (enterprise)\n */\nexport type EditModel =\n    | {\n          [K in keyof Models]: HasUsage<Models[K], ModelUsage.Edit>\n      }[keyof Models]['model']\n    | (string & {})\n\n/**\n * Available models for Chat.\n * This is either:\n * - one of the availble options (dotcom)\n * - an unknown `string` (enterprise)\n */\nexport type ChatModel =\n    | {\n          [K in keyof Models]: HasUsage<Models[K], ModelUsage.Chat>\n      }[keyof Models]['model']\n    | (string & {})\n\nexport interface ModelContextWindow {\n    /**\n     * The token limit reserved for chat input.\n     */\n    input: number\n    /**\n     * The maximum number of tokens that the model can respond with in a single request.\n     */\n    output: number\n    /**\n     * The additional tokens reserved for context.\n     * When not defined, context shares the same token limit as input.\n     */\n    context?: {\n        /**\n         * The token limit reserved for user-added context.\n         * Example: @-mentions.\n         */\n        user?: number\n    }\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/supercompletions/prompt.ts:2-2","content":"export const MODEL = 'anthropic/claude-3-haiku-20240307'\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/context-ranking.ts:226-254","content":"    }\n\n    public async retrieveEmbeddingBasedContext(\n        query: PromptString,\n        numResults: number,\n        modelName: string\n    ): Promise<EmbeddingsSearchResult[]> {\n        const repoUri = this.getRepoUri()\n        if (!repoUri || !this.endpointIsDotcom || !this.serviceStarted) {\n            return []\n        }\n        try {\n            const service = await this.getService()\n            const resp = await service.request('context-ranking/context-retriever-embedding', {\n                repoPath: repoUri.path,\n                query: query.toString(),\n                modelName: modelName,\n                numResults: numResults,\n            })\n            const model_specific_embedding_items = resp.results.map(result => ({\n                ...result,\n                uri: vscode.Uri.joinPath(repoUri, result.fileName),\n            }))\n            return model_specific_embedding_items\n        } catch (error) {\n            logDebug(\n                'ContextRankingController',\n                'error in fetching embeddings features',\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/context-ranking.ts:286-313","content":"                'getEnhancedContext > searching model specific embeddings'\n            )\n            const contextItems: ContextItem[] = []\n            const modelName = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n            const embeddingsResults = await this.retrieveEmbeddingBasedContext(\n                text,\n                numResults,\n                modelName\n            )\n            for (const result of embeddingsResults) {\n                const range = new vscode.Range(\n                    new vscode.Position(result.startLine, 0),\n                    new vscode.Position(result.endLine, 0)\n                )\n\n                contextItems.push({\n                    type: 'file',\n                    uri: result.uri,\n                    range,\n                    content: result.content,\n                    source: ContextItemSource.Embeddings,\n                })\n            }\n            return contextItems\n        })\n    }\n}\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/jsonrpc/context-ranking-protocol.ts:0-57","content":"import type { QueryResultSet } from './embeddings-protocol'\n\ninterface InitializeParams {\n    indexPath: string\n    accessToken: string\n}\n\ninterface ComputeFeaturesParams {\n    repoPath: string\n}\n\nexport interface RankContextItem {\n    documentId: number\n    filePath?: string\n    content: string\n    source?: string\n}\n\ninterface RankItemsParams {\n    repoPath: string\n    query: string\n    contextItems: RankContextItem[]\n}\n\ninterface RankerPredictions {\n    prediction: RankerPrediction[]\n}\n\nexport interface RankerPrediction {\n    document_id: number\n    score: number\n}\n\nexport interface EmbeddingModelQueryParams {\n    repoPath: string\n    query: string\n    modelName: string\n    numResults: number\n}\n\nexport interface PrecomputeEmbeddingsParams {\n    query: string\n}\n\nexport type Requests = {\n    'context-ranking/echo': [string, string]\n    'context-ranking/initialize': [InitializeParams, string]\n    'context-ranking/compute-features': [ComputeFeaturesParams, string]\n    'context-ranking/rank-items': [RankItemsParams, RankerPredictions]\n    'context-ranking/context-retriever-embedding': [EmbeddingModelQueryParams, QueryResultSet]\n    'context-ranking/precompute-query-embedding': [PrecomputeEmbeddingsParams, string]\n}\n\nexport type Notifications = {\n    'context-ranking/rank-items-logger-payload': [string]\n}\n"}]

 class: Find logic
