 question: What different context ranking logics are implemented in Cody?
# CHAT
# CHAT_QUESTION What different context ranking logics are implemented in Cody?

# CHAT_REPLY Based on the provided code context, Cody implements the following context ranking logics:
# CHAT_REPLY 
# CHAT_REPLY 1. **Ranking Context Items using a Machine Learning Model**: The `ContextRankingController` class in `context-ranking.ts` has a `rankContextItems` method that takes a query and a list of `ContextItem` objects. It then converts these `ContextItem` objects to `RankContextItem` objects and sends them to a service (likely a child process) via a JSON-RPC request (`context-ranking/rank-items`). The service returns a ranked list of `RankerPrediction` objects, which are used to reorder the original `ContextItem` list.
# CHAT_REPLY 
# CHAT_REPLY 2. **Retrieving Context using Embeddings**: The `ContextRankingController` also has a `retrieveEmbeddingBasedContext` method that retrieves context items based on embeddings. It sends a JSON-RPC request (`context-ranking/context-retriever-embedding`) with a query, model name, and the number of results to retrieve. The service returns a list of `EmbeddingsSearchResult` objects, which are then converted to `ContextItem` objects.
# CHAT_REPLY 
# CHAT_REPLY 3. **Precomputing Context Ranking Features**: The `precomputeContextRankingFeatures` method in `ContextRankingController` sends a JSON-RPC request (`context-ranking/precompute-query-embedding`) to precompute features for a given query, likely to speed up subsequent ranking requests.
# CHAT_REPLY 
# CHAT_REPLY 4. **Searching Model-Specific Embeddings**: The `searchModelSpecificEmbeddings` method in `ContextRankingController` retrieves context items using a specific model (in this case, `sentence-transformers/multi-qa-mpnet-base-dot-v1`) by calling the `retrieveEmbeddingBasedContext` method.
# CHAT_REPLY 
# CHAT_REPLY The actual ranking and embedding retrieval logic seems to be implemented in a separate service that communicates with the extension via JSON-RPC. The `ContextRankingController` acts as a client to this service, handling the communication and converting data structures as needed.

# CONTEXT_ITEMS [{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/walkthroughs/keyboard.md:0-19","content":"## Keyboard Shortcuts\n\nCody offers an extensive set of default key bindings (keyboard shortcuts) to make it easy for you to perform various actions using the keyboard. You can also update these bindings in the `Keyboard Shortcuts Editor`.\n\n### Keyboard Shortcuts Editor\n\nThe `Keyboard Shortcuts Editor` allows you to easily update the default bindings (keyboard shortcuts). This is particularly useful if the default key bindings conflict with your current or preferred key bindings. By accessing the `Keyboard Shortcuts Editor`, you can search for specific commands, reassign keybindings, and customize your keyboard shortcuts to suit your workflow.\n\n### Getting Started\n\nTo get started: \n1. Click on the **Keyboard Shortcuts** icon in the Cody sidebar under `**SETTINGS AND SUPPORT**` to open the `Keyboard Shortcuts Editor`.\n2. In the `Keyboard Shortcuts Editor`, you can search for a specific command by typing in the search bar.\n3. Once you have found the command you want to reassign keybindings for, click on it to select it.\n4. Follow the instruction on screen to assign a new keybinding.\n\n**✨ Pro-tips for assigning keyboard shortcuts for Cody**\n<br>• You can assign key bindings (keyboard shortcuts) to individual custom commands.\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/CHANGELOG.md:985-1005","content":"\n## [0.12.1]\n\n### Added\n\n### Fixed\n\n- Fixes an issue that caused the `cody-autocomplete-claude-instant-infill` feature flag to have no effect. [pull/1132](https://github.com/sourcegraph/cody/pull/1132)\n\n### Changed\n\n## [0.12.0]\n\n### Added\n\n- Add a UI indicator when you're not signed in. [pull/970](https://github.com/sourcegraph/cody/pull/970)\n- Added a completion statistics summary to the autocomplete trace view. [pull/973](https://github.com/sourcegraph/cody/pull/973)\n- Add experimental option `claude-instant-infill` to the `cody.autocomplete.advanced.model` config option that enables users using the Claude Instant model to get suggestions with context awareness (infill). [pull/974](https://github.com/sourcegraph/cody/pull/974)\n- New `cody.chat.preInstruction` configuration option for adding custom message at the start of all chat messages sent to Cody. Extension reload required. [pull/963](https://github.com/sourcegraph/cody/pull/963)\n- Add a simplified sign-in. 50% of people will see these new sign-in buttons. [pull/1036](https://github.com/sourcegraph/cody/pull/1036)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/doc/dev/quality/index.md:0-16","content":"# Cody quality tools\n\nThis section documents the tools we have to assess the quality of Cody in different scenarios.\n\nAs Cody is a BYOLLM product (Bring-your-own-LLM), when we introduce/use a new LLM (for example, a customer's own LLM model that they developed/trained themselves) we have a need to be able to quantify how well Cody is working with it.\n\n## Autocompletion\n\n### Influencing autocomplete performance\n\nCody autocompletion (code completions in your editor) can be powered by two types of models:\n\n1. Chat-based models, where we \"tell\" the LLM it supposed to perform code completion in plain English, give it a code snippet, and extract the response code snippet from its (otherwise English) response.\n2. An actual code-based model, these are LLMs that are trained to produce code only and can't produce English responses, they speak only code.\n\nFor chat-based models, we can influence the performance by altering the prompting AND context. For code-based models, we can typically influence the performance by adjusting the amount and relevancy of context only, as there is no prompting to adjust.\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:940-962","content":"          \"examples\": [\"Answer all my questions in Spanish.\"]\n        },\n        \"cody.edit.preInstruction\": {\n          \"order\": 7,\n          \"type\": \"string\",\n          \"markdownDescription\": \"A custom instruction to be included at the end of all instructions for edit commands (e.g. \\\"Write all unit tests with Jest instead of detected framework.\\\")\",\n          \"examples\": [\"Write all unit tests with Jest instead of detected framework.\"]\n        },\n        \"cody.codeActions.enabled\": {\n          \"order\": 11,\n          \"title\": \"Cody Code Actions\",\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Add Cody options to Quick Fix menus for fixing, explaining, documenting, and editing code.\",\n          \"default\": true\n        },\n        \"cody.commandHints.enabled\": {\n          \"order\": 12,\n          \"title\": \"Cody Command Hints\",\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Enable hints for Cody commands such as \\\"Opt+K to Edit\\\" or \\\"Opt+D to Document\\\"\",\n          \"default\": true\n        },\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/experimentation/FeatureFlagProvider.ts:34-54","content":"\n    // use-ssc-for-cody-subscription is a feature flag that enables the use of SSC as the source of truth for Cody subscription data.\n    UseSscForCodySubscription = 'use-ssc-for-cody-subscription',\n\n    // cody-pro-trial-ended is a feature flag that indicates if the Cody Pro \"Free Trial\"  has ended.\n    // (Enabling users to use Cody Pro for free for 3-months starting in late Q4'2023.)\n    CodyProTrialEnded = 'cody-pro-trial-ended',\n\n    // Show document hints above a symbol if the users' cursor is there. \"Opt+D to Document\"\n    CodyDocumentHints = 'cody-document-hints',\n\n    /** Support @-mentioning URLs in chat to add context from web pages. */\n    URLContext = 'cody-url-context',\n\n    /** Display Cody commands in a pop-up window on hover. */\n    CodyHoverCommands = 'cody-hover-commands',\n\n    /** Apply a higher context window for user context items (e.g., @-mentions). */\n    CodyChatContextBudget = 'cody-chat-context-budget',\n}\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/CHANGELOG.md:151-166","content":"- Command: Enhanced the context provided to the Test command to help the language model determine the appropriate testing framework to use. [pull/3344](https://github.com/sourcegraph/cody/pull/3344)\n- Document: Upgraded to use a faster model. [pull/3275](https://github.com/sourcegraph/cody/pull/3275)\n- Properly throw an error when attempting to parse an incomplete SSE stream with the nodeClient. [pull/3479](https://github.com/sourcegraph/cody/pull/3479)\n\n## [1.8.3]\n\n### Fixed\n\n- Fix crash upon initialization in the stable build if a prerelease version of the VS Code extension was used for chat after 2024-03-08. [pull/3394](https://github.com/sourcegraph/cody/pull/3394)\n\n## [1.8.2]\n\n### Added\n\n- Debug: Added new commands (`Cody Debug: Enable Debug Mode` and `Cody Debug: Open Output Channel`) to the editor Command Palette and the `Settings & Support` sidebar to streamline the process of getting started with debugging Cody. [pull/3342](https://github.com/sourcegraph/cody/pull/3342)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/CHANGELOG.md:1123-1136","content":"\n- Cody Commands: Add tab-to-complete & enter-to-complete behavior. [pull/606](https://github.com/sourcegraph/cody/pull/606)\n- Option to toggle `cody.experimental.editorTitleCommandIcon` setting through status bar. [pull/611](https://github.com/sourcegraph/cody/pull/611)\n- New walkthrough for Cody Commands. [pull/648](https://github.com/sourcegraph/cody/pull/648)\n\n### Fixed\n\n- Update file link color to match buttons. [pull/600](https://github.com/sourcegraph/cody/pull/600)\n- Handle `socket hung up` errors that are not caused by the `stop generating` button. [pull/598](https://github.com/sourcegraph/cody/pull/598)\n- Fix \"Reload Window\" appearing in all VS Code views. [pull/603](https://github.com/sourcegraph/cody/pull/603)\n- Fixes issues where in some instances, suggested autocomplete events were under counted. [pull/649](https://github.com/sourcegraph/cody/pull/649)\n- Various smaller tweaks to autocomplete analytics. [pull/644](https://github.com/sourcegraph/cody/pull/644)\n- Includes the correct pre-release version in analytics events. [pull/641](https://github.com/sourcegraph/cody/pull/641)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/CHANGELOG.md:0-24","content":"# Changelog\n\nThis is a log of all notable changes to Cody for VS Code. [Unreleased] changes are included in the nightly pre-release builds.\n\n## [Unreleased]\n\n### Added\n\n### Fixed\n\n- Chat: Fixed an issue where Cody's responses were not visible in small windows. [pull/3859](https://github.com/sourcegraph/cody/pull/3859)\n- Edit: Fixed an issue where an Edit task would not correctly respin when an irresolvable conflict is encountered. [pull/3872](https://github.com/sourcegraph/cody/pull/3872)\n- Chat: Fixed an issue where older chats were displaying as 'N months ago' instead of the number in the Chat History sidebar. [pull/3864](https://github.com/sourcegraph/cody/pull/3864)\n\n### Changed\n\n- Debug: Removed the `cody.debug.enabled` setting. Baseline debugging is now enabled by default [pull/3873](https://github.com/sourcegraph/cody/pull/3873)\n\n\n## [1.14.0]\n\n### Added\n\n- Chat: Add highlighted code to Cody Chat as `@-mentions` context by right-clicking on the code and selecting `Cody Chat: Add context`. [pull/3713](https://github.com/sourcegraph/cody/pull/3713)\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:1050-1068","content":"          \"markdownDescription\": \"Prevent autocomplete requests while inside code comments.\"\n        },\n        \"cody.experimental.foldingRanges\": {\n          \"type\": \"string\",\n          \"enum\": [\"lsp\", \"indentation-based\"],\n          \"enumDescriptions\": [\n            \"Use folding ranges that are enabled by default in VS Code, and are usually powered by LSP\",\n            \"Use custom implementation of folding ranges that is indentation based. This is the implementation that is used by other Cody clients like the JetBrains plugin\"\n          ],\n          \"markdownDescription\": \"Determines the algorithm Cody uses to detect folding ranges. Cody uses folding ranges for several features like the 'Document code' command\",\n          \"default\": \"all\"\n        },\n        \"cody.experimental.hoverCommands\": {\n          \"type\": \"boolean\",\n          \"default\": true,\n          \"markdownDescription\": \"Display commands in hover tooltips for code elements.\",\n          \"description\": \"%config.experimental.hoverCommands%\",\n          \"tags\": [\"experimental\", \"feature-flag\"]\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/doc/keyboard.md:0-18","content":"# Keyboard Shortcuts\n\nCody offers an extensive set of default key bindings (keyboard shortcuts) to make it easy for you to perform various actions using the keyboard. You can easily update these bindings in the `Keyboard Shortcuts editor`, which you can access by clicking on the **Keyboard Shortcuts** icon in the Cody sidebar under `**SETTINGS AND SUPPORT**`.\n\nThis feature can be particularly useful if the default key bindings conflict with your current or preferred key bindings.\n\n## Keyboard Shortcuts Editor\n\nThe Keyboard Shortcuts editor allows you to easily update the key bindings for any of the Cody commands. To open the `Keyboard Shortcuts Editor`:\n1. Open the Cody sidebar and expand the `**SETTINGS AND SUPPORT**` section.\n2. Click on the `**Keyboard Shortcuts**` icon.\n\n## Custom Commands\n\n![editor](images/keyboard_editor.png)\n\nYou have the option to assign key bindings (keyboard shortcuts) to individual custom commands:\n1. In the Cody sidebar under `**SETTINGS AND SUPPORT**`, click on the `**Keyboard Shortcuts**` icon to open the Keyboard Shortcuts editor.\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/lib/shared/src/commands/types.ts:0-32","content":"// The default Cody Commands\nexport type DefaultCodyCommands = DefaultChatCommands | DefaultEditCommands\n\n// Default Cody Commands that runs as a Chat request\nexport enum DefaultChatCommands {\n    Explain = 'explain', // Explain code\n    Unit = 'unit', // Generate unit tests in Chat\n    Smell = 'smell', // Generate code smell report in Chat\n}\n\n// Default Cody Commands that runs as an Inline Edit command\nexport enum DefaultEditCommands {\n    Test = 'test', // Generate unit tests with inline edit\n    Doc = 'doc', // Generate documentation with inline edit\n    Edit = 'edit', // Edit code with inline edit\n}\n\n// The blueprint of a Cody Custom Command\nexport interface CodyCommand {\n    /**\n     * @deprecated Use 'commandKey' instead.\n     */\n    slashCommand?: string\n    /**\n     * key of the command, e.g. 'smell' for Code Smell\n     */\n    key: string\n    prompt: string\n    description?: string\n    context?: CodyCommandContext\n    type?: CodyCommandType\n    mode?: CodyCommandMode\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:909-940","content":"            \"*\": true\n          },\n          \"examples\": [\n            {\n              \"*\": true,\n              \"plaintext\": false\n            }\n          ]\n        },\n        \"cody.commandCodeLenses\": {\n          \"order\": 8,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Adds code lenses to current file for quick access to Cody commands.\",\n          \"default\": false\n        },\n        \"cody.experimental.guardrails\": {\n          \"order\": 9,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Experimental feature for internal use.\",\n          \"default\": false\n        },\n        \"cody.experimental.localSymbols\": {\n          \"order\": 9,\n          \"type\": \"boolean\",\n          \"default\": false,\n          \"markdownDescription\": \"Experimental feature for internal use.\"\n        },\n        \"cody.chat.preInstruction\": {\n          \"order\": 6,\n          \"type\": \"string\",\n          \"markdownDescription\": \"A custom instruction to be included at the start of all chat messages (e.g. \\\"Answer all my questions in Spanish.\\\")\",\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/local-context/context-ranking.ts:0-313","content":"import * as fspromises from 'node:fs/promises'\nimport * as path from 'node:path'\nimport {\n    type ConfigurationWithAccessToken,\n    type ContextItem,\n    ContextItemSource,\n    type EmbeddingsSearchResult,\n    type FileURI,\n    type PromptString,\n    isDotCom,\n    isFileURI,\n    wrapInActiveSpan,\n} from '@sourcegraph/cody-shared'\nimport * as vscode from 'vscode'\nimport { URI } from 'vscode-uri'\nimport type { RankContextItem, RankerPrediction } from '../jsonrpc/context-ranking-protocol'\nimport type { MessageHandler } from '../jsonrpc/jsonrpc'\nimport { logDebug } from '../log'\nimport { captureException } from '../services/sentry/sentry'\nimport { CodyEngineService } from './cody-engine'\n\ninterface ContextRanker {\n    rankContextItems(query: PromptString, contextItems: ContextItem[]): Promise<ContextItem[]>\n}\n\nexport function createContextRankingController(\n    context: vscode.ExtensionContext,\n    config: ContextRankerConfig\n): ContextRankingController {\n    return new ContextRankingController(context, config)\n}\n\nexport type ContextRankerConfig = Pick<\n    ConfigurationWithAccessToken,\n    'serverEndpoint' | 'accessToken'\n> & { experimentalChatContextRanker: boolean | undefined }\n\nfunction getIndexLibraryPath(): FileURI {\n    switch (process.platform) {\n        case 'darwin':\n            return URI.file(`${process.env.HOME}/Library/Caches/com.sourcegraph.cody/context-ranking`)\n        case 'linux':\n            return URI.file(`${process.env.HOME}/.cache/com.sourcegraph.cody/context-ranking`)\n        case 'win32':\n            return URI.file(`${process.env.LOCALAPPDATA}\\\\com.sourcegraph.cody\\\\context-ranking`)\n        default:\n            throw new Error(`Unsupported platform: ${process.platform}`)\n    }\n}\n\nexport class ContextRankingController implements ContextRanker {\n    // The cody-engine child process, if starting or started.\n    private service: Promise<MessageHandler> | undefined\n    // True if the service has finished starting and been initialized.\n    private serviceStarted = false\n    // Whether the account is a consumer account.\n    private endpointIsDotcom = false\n    private accessToken: string | undefined\n    private readonly indexLibraryPath: FileURI | undefined\n\n    constructor(\n        private readonly context: vscode.ExtensionContext,\n        config: ContextRankerConfig\n    ) {\n        this.endpointIsDotcom = isDotCom(config.serverEndpoint)\n        this.accessToken = config.accessToken || undefined\n        logDebug('ContextRankingController', 'constructor')\n    }\n\n    public async start(): Promise<void> {\n        logDebug('ContextRankingController', 'start')\n        await this.getService()\n\n        const repoUri = this.getRepoUri()\n        if (repoUri && isFileURI(repoUri)) {\n            this.computeFeatures(repoUri)\n        }\n    }\n\n    public async setAccessToken(serverEndpoint: string, token: string | null): Promise<void> {\n        const endpointIsDotcom = isDotCom(serverEndpoint)\n        logDebug(\n            'ContextRankingController',\n            'setAccessToken',\n            endpointIsDotcom ? 'is dotcom' : 'not dotcom'\n        )\n        this.endpointIsDotcom = endpointIsDotcom\n        if (token === this.accessToken) {\n            return Promise.resolve()\n        }\n        this.accessToken = token || undefined\n    }\n\n    private getRepoUri(): vscode.Uri | undefined {\n        return vscode.workspace.workspaceFolders?.[0]?.uri\n    }\n\n    // Tries to compute the index at the start of the service.\n    private async computeFeatures(repoDir: FileURI): Promise<void> {\n        try {\n            await (await this.getService()).request('context-ranking/compute-features', {\n                repoPath: repoDir.fsPath,\n            })\n        } catch (error) {\n            logDebug(\n                'ContextRankingController',\n                'error in feature preCompute call',\n                captureException(error),\n                JSON.stringify(error)\n            )\n        }\n    }\n\n    private getService(): Promise<MessageHandler> {\n        if (!this.service) {\n            const instance = CodyEngineService.getInstance(this.context)\n            this.service = instance.getService(this.setupContextRankingService)\n        }\n        return this.service\n    }\n\n    private async createLogsFile(dirPath: string): Promise<string> {\n        await fspromises.mkdir(dirPath, { recursive: true })\n        const fileName = 'ranker-payload.jsonl'\n        const filePath = path.join(dirPath, fileName)\n        if (\n            !(await fspromises\n                .access(filePath)\n                .then(() => true)\n                .catch(() => false))\n        ) {\n            await fspromises.writeFile(filePath, '')\n        }\n        return filePath\n    }\n\n    private setupContextRankingService = async (service: MessageHandler): Promise<void> => {\n        // The payload is very big to print on console. SKipping print on console for now until we start logging in BQ.\n        service.registerNotification(\n            'context-ranking/rank-items-logger-payload',\n            async (payload: string) => {\n                const indexPath = getIndexLibraryPath()\n                const logsFile = await this.createLogsFile(path.join(indexPath.fsPath, 'ranker-logs'))\n                fspromises.appendFile(logsFile, payload + '\\n')\n                logDebug(\n                    'ContextRankingController',\n                    'rank-items-logger-payload',\n                    'appending logs at the path',\n                    logsFile\n                )\n            }\n        )\n        let indexPath = getIndexLibraryPath()\n        // Tests may override the index library path\n        if (this.indexLibraryPath) {\n            indexPath = this.indexLibraryPath\n        }\n        if (this.accessToken) {\n            await service.request('context-ranking/initialize', {\n                indexPath: indexPath.fsPath,\n                accessToken: this.accessToken,\n            })\n            this.serviceStarted = true\n        } else {\n            logDebug('ContextRankingController', 'setupContextRankingService', 'no access token found')\n        }\n    }\n\n    public async rankContextItems(\n        query: PromptString,\n        contextItems: ContextItem[]\n    ): Promise<ContextItem[]> {\n        const repoUri = this.getRepoUri()\n        if (!repoUri || !this.endpointIsDotcom || !this.serviceStarted) {\n            return contextItems\n        }\n\n        try {\n            const service = await this.getService()\n            const rankItems = this.convertContextItemsToRankItems(repoUri.fsPath, contextItems)\n            const rankedItemsOrder = await service.request('context-ranking/rank-items', {\n                repoPath: repoUri.path,\n                contextItems: rankItems,\n                query: query.toString(),\n            })\n\n            if (rankedItemsOrder.prediction.length !== contextItems.length) {\n                return contextItems\n            }\n            const reRankedContextItems = this.orderContextItemsAsRankItems(\n                contextItems,\n                rankedItemsOrder.prediction\n            )\n            return reRankedContextItems\n        } catch (error) {\n            return contextItems\n        }\n    }\n\n    private convertContextItemsToRankItems(\n        baseRepoPath: string,\n        contextItems: ContextItem[]\n    ): RankContextItem[] {\n        const rankContextItems = contextItems.map((item, index) => ({\n            documentId: index,\n            filePath: item.uri?.path ? path.relative(baseRepoPath, item.uri?.path) : '',\n            content: item.content ?? '',\n            source: item.source,\n        }))\n        return rankContextItems\n    }\n\n    private orderContextItemsAsRankItems(\n        contextItems: ContextItem[],\n        rankedItemsOrder: RankerPrediction[]\n    ): ContextItem[] {\n        rankedItemsOrder.sort((a, b) => b.score - a.score)\n        const orderedContextItems: ContextItem[] = []\n        for (const item of rankedItemsOrder) {\n            const newIndex = item.document_id\n            if (newIndex < 0 || newIndex >= contextItems.length) {\n                return contextItems\n            }\n            orderedContextItems.push(contextItems[newIndex])\n        }\n        return orderedContextItems\n    }\n\n    public async retrieveEmbeddingBasedContext(\n        query: PromptString,\n        numResults: number,\n        modelName: string\n    ): Promise<EmbeddingsSearchResult[]> {\n        const repoUri = this.getRepoUri()\n        if (!repoUri || !this.endpointIsDotcom || !this.serviceStarted) {\n            return []\n        }\n        try {\n            const service = await this.getService()\n            const resp = await service.request('context-ranking/context-retriever-embedding', {\n                repoPath: repoUri.path,\n                query: query.toString(),\n                modelName: modelName,\n                numResults: numResults,\n            })\n            const model_specific_embedding_items = resp.results.map(result => ({\n                ...result,\n                uri: vscode.Uri.joinPath(repoUri, result.fileName),\n            }))\n            return model_specific_embedding_items\n        } catch (error) {\n            logDebug(\n                'ContextRankingController',\n                'error in fetching embeddings features',\n                captureException(error)\n            )\n            return []\n        }\n    }\n\n    public async precomputeContextRankingFeatures(query: PromptString): Promise<void> {\n        const repoUri = this.getRepoUri()\n        if (!repoUri || !this.endpointIsDotcom || !this.serviceStarted) {\n            return\n        }\n        try {\n            const service = await this.getService()\n            await service.request('context-ranking/precompute-query-embedding', {\n                query: query.toString(),\n            })\n        } catch (error) {\n            logDebug(\n                'ContextRankingController',\n                'error in fetching embeddings features',\n                captureException(error)\n            )\n        }\n    }\n\n    public async searchModelSpecificEmbeddings(\n        text: PromptString,\n        numResults: number\n    ): Promise<ContextItem[]> {\n        return wrapInActiveSpan('chat.context.model-specific-embeddings.local', async () => {\n            logDebug(\n                'SimpleChatPanelProvider',\n                'getEnhancedContext > searching model specific embeddings'\n            )\n            const contextItems: ContextItem[] = []\n            const modelName = 'sentence-transformers/multi-qa-mpnet-base-dot-v1'\n            const embeddingsResults = await this.retrieveEmbeddingBasedContext(\n                text,\n                numResults,\n                modelName\n            )\n            for (const result of embeddingsResults) {\n                const range = new vscode.Range(\n                    new vscode.Position(result.startLine, 0),\n                    new vscode.Position(result.endLine, 0)\n                )\n\n                contextItems.push({\n                    type: 'file',\n                    uri: result.uri,\n                    range,\n                    content: result.content,\n                    source: ContextItemSource.Embeddings,\n                })\n            }\n            return contextItems\n        })\n    }\n}\n"},{"source":"search","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/src/jsonrpc/context-ranking-protocol.ts:0-56","content":"import type { QueryResultSet } from './embeddings-protocol'\n\ninterface InitializeParams {\n    indexPath: string\n    accessToken: string\n}\n\ninterface ComputeFeaturesParams {\n    repoPath: string\n}\n\nexport interface RankContextItem {\n    documentId: number\n    filePath?: string\n    content: string\n    source?: string\n}\n\ninterface RankItemsParams {\n    repoPath: string\n    query: string\n    contextItems: RankContextItem[]\n}\n\ninterface RankerPredictions {\n    prediction: RankerPrediction[]\n}\n\nexport interface RankerPrediction {\n    document_id: number\n    score: number\n}\n\nexport interface EmbeddingModelQueryParams {\n    repoPath: string\n    query: string\n    modelName: string\n    numResults: number\n}\n\nexport interface PrecomputeEmbeddingsParams {\n    query: string\n}\n\nexport type Requests = {\n    'context-ranking/echo': [string, string]\n    'context-ranking/initialize': [InitializeParams, string]\n    'context-ranking/compute-features': [ComputeFeaturesParams, string]\n    'context-ranking/rank-items': [RankItemsParams, RankerPredictions]\n    'context-ranking/context-retriever-embedding': [EmbeddingModelQueryParams, QueryResultSet]\n    'context-ranking/precompute-query-embedding': [PrecomputeEmbeddingsParams, string]\n}\n\nexport type Notifications = {\n    'context-ranking/rank-items-logger-payload': [string]\n}\n"},{"source":"embeddings","file":"/Users/jan/repos/cody-leaderboard/input/chat-context/cody_test/vscode/package.json:993-1016","content":"          \"order\": 99,\n          \"type\": \"boolean\",\n          \"markdownDescription\": \"Enables verbose debug output. Debug messages may contain more details if the invocation includes verbose information.\"\n        },\n        \"cody.debug.filter\": {\n          \"order\": 99,\n          \"type\": \"string\",\n          \"markdownDescription\": \"Regular expression to filter debug output. If empty, defaults to '.*', which prints all messages.\"\n        },\n        \"cody.telemetry.level\": {\n          \"order\": 99,\n          \"type\": \"string\",\n          \"enum\": [\"all\", \"off\"],\n          \"enumDescriptions\": [\"Sends usage data and errors.\", \"Disables all extension telemetry.\"],\n          \"markdownDescription\": \"Controls the telemetry about Cody usage and errors. See [Cody usage and privacy notice](https://about.sourcegraph.com/terms/cody-notice).\",\n          \"default\": \"all\"\n        },\n        \"cody.autocomplete.advanced.provider\": {\n          \"type\": \"string\",\n          \"default\": null,\n          \"enum\": [\n            null,\n            \"anthropic\",\n"}]

 class: Gather information
